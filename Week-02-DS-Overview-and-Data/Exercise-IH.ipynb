{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you’ll―of course―overcome them with what you learned in class! 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>cook</th>\n",
       "      <th>comfort_food_reasons_coded.1</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>diet_current</th>\n",
       "      <th>diet_current_coded</th>\n",
       "      <th>drink</th>\n",
       "      <th>eating_changes</th>\n",
       "      <th>eating_changes_coded</th>\n",
       "      <th>eating_changes_coded1</th>\n",
       "      <th>eating_out</th>\n",
       "      <th>employment</th>\n",
       "      <th>ethnic_food</th>\n",
       "      <th>exercise</th>\n",
       "      <th>father_education</th>\n",
       "      <th>father_profession</th>\n",
       "      <th>fav_cuisine</th>\n",
       "      <th>fav_cuisine_coded</th>\n",
       "      <th>fav_food</th>\n",
       "      <th>...</th>\n",
       "      <th>healthy_feeling</th>\n",
       "      <th>healthy_meal</th>\n",
       "      <th>ideal_diet</th>\n",
       "      <th>ideal_diet_coded</th>\n",
       "      <th>income</th>\n",
       "      <th>indian_food</th>\n",
       "      <th>italian_food</th>\n",
       "      <th>life_rewarding</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>meals_dinner_friend</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>mother_profession</th>\n",
       "      <th>nutritional_check</th>\n",
       "      <th>on_off_campus</th>\n",
       "      <th>parents_cook</th>\n",
       "      <th>pay_meal_out</th>\n",
       "      <th>persian_food</th>\n",
       "      <th>self_perception_weight</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eat good and exercise</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eat faster</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>profesor</td>\n",
       "      <td>Arabic cuisine</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>looks not oily</td>\n",
       "      <td>being healthy</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rice, chicken,  soup</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>car racing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I eat about three times a day with some snacks...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I eat out more than usual.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>Italian</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Grains, Veggies, (more of grains and veggies),...</td>\n",
       "      <td>Try to eat 5-6 small meals a day. While trying...</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Pasta, steak, chicken</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Nurse RN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>toast and fruit for breakfast, salad for lunch...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sometimes choosing to eat fast food instead of...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>owns business</td>\n",
       "      <td>italian</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>usually includes natural ingredients; nonproce...</td>\n",
       "      <td>i would say my ideal diet is my current diet</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>chicken and rice with veggies, pasta, some kin...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>owns business</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>College diet, cheap and easy foods most nights...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Accepting cheap and premade/store bought foods</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Mechanic</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>Fresh fruits&amp; vegetables, organic meats</td>\n",
       "      <td>Healthy, fresh veggies/fruits &amp; organic foods</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Grilled chicken \\rStuffed Shells\\rHomemade Chili</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Special Education Teacher</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I try to eat healthy but often struggle becaus...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have eaten generally the same foods but I do...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>IT</td>\n",
       "      <td>Italian</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>A lean protein such as grilled chicken, green ...</td>\n",
       "      <td>Ideally I would like to be able to eat healthi...</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Chicken Parmesan, Pulled Pork, Spaghetti and m...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Substance Abuse Conselor</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>wine. mac and cheese, pizza, ice cream</td>\n",
       "      <td>boredom and sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My diet consists mainly of coffee, water, frui...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have noticed there is less time for a prepar...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Italian</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>mainly protein and vegetables with a complex c...</td>\n",
       "      <td>My ideal diet would consist of a majority of w...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pasta, fish, steak</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Radiological Technician</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>2.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza / Wings / Cheesecake</td>\n",
       "      <td>Loneliness / Homesick / Sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A college student with an imbalanced diet tryi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Eating Pizza as an excuse when there is nothin...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>Mexican Food</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>A healthy meal is a variety of food , organic ...</td>\n",
       "      <td>Eating home cooked meals everyday and being ab...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fried Rice \\rBaked potatoes \\rCurry Chicken</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Public Health Advisor</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>basketball</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3.882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>rice, potato, seaweed soup</td>\n",
       "      <td>sadness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rice, oatmeal, and tea</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>less rice</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CEO of company</td>\n",
       "      <td>Korean</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>lots of vegetables</td>\n",
       "      <td>lots of veggies</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>meat, rice, kimchi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Real Estate manageer</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>580.0</td>\n",
       "      <td>690</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mac n Cheese, Lasagna, Pizza</td>\n",
       "      <td>happiness, they are some of my favorite foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I try to eat as healthy as possible everyday. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I don't eat as much on a daily basis since com...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Store manager at Giant Eagle</td>\n",
       "      <td>Italian</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>A protein, a fruit, a starch, and a salad or s...</td>\n",
       "      <td>My ideal diet is the diet i am currently on.  ...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Pizza, Spaghetti, Baked Ziti</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Receptionist for a medical supply company</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolates, pizza, and Ritz.</td>\n",
       "      <td>hormones, Premenstrual syndrome.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>high in protein and low in carbohydrates.</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have learned to eat more vegetables.</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Journalist</td>\n",
       "      <td>HISPANIC CUISINE.</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>a cup of rice, vegetables, and meat.</td>\n",
       "      <td>Being able to balance between sweets, vegetabl...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Vegetables, Meat, and rice.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>House-wife</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>575</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0      2.4       2          1               430           NaN           315.0   \n",
       "1    3.654       1          1               610           3.0           420.0   \n",
       "2      3.3       1          1               720           4.0           420.0   \n",
       "3      3.2       1          1               430           3.0           420.0   \n",
       "4      3.5       1          1               720           2.0           420.0   \n",
       "..     ...     ...        ...               ...           ...             ...   \n",
       "120    3.5       1          1               610           4.0           420.0   \n",
       "121      3       1          1               265           2.0           315.0   \n",
       "122  3.882       1          1               720           NaN           420.0   \n",
       "123      3       2          1               720           4.0           420.0   \n",
       "124    3.9       1          1               430           NaN           315.0   \n",
       "\n",
       "     coffee                             comfort_food  \\\n",
       "0         1                                     none   \n",
       "1         2              chocolate, chips, ice cream   \n",
       "2         2          frozen yogurt, pizza, fast food   \n",
       "3         2         Pizza, Mac and cheese, ice cream   \n",
       "4         2             Ice cream, chocolate, chips    \n",
       "..      ...                                      ...   \n",
       "120       2  wine. mac and cheese, pizza, ice cream    \n",
       "121       2               Pizza / Wings / Cheesecake   \n",
       "122       1               rice, potato, seaweed soup   \n",
       "123       1             Mac n Cheese, Lasagna, Pizza   \n",
       "124       2             Chocolates, pizza, and Ritz.   \n",
       "\n",
       "                              comfort_food_reasons  \\\n",
       "0                            we dont have comfort    \n",
       "1                             Stress, bored, anger   \n",
       "2                                  stress, sadness   \n",
       "3                                          Boredom   \n",
       "4                       Stress, boredom, cravings    \n",
       "..                                             ...   \n",
       "120                           boredom and sadness    \n",
       "121                Loneliness / Homesick / Sadness   \n",
       "122                                        sadness   \n",
       "123  happiness, they are some of my favorite foods   \n",
       "124               hormones, Premenstrual syndrome.   \n",
       "\n",
       "     comfort_food_reasons_coded  cook  comfort_food_reasons_coded.1  cuisine  \\\n",
       "0                           9.0   2.0                             9      NaN   \n",
       "1                           1.0   3.0                             1      1.0   \n",
       "2                           1.0   1.0                             1      3.0   \n",
       "3                           2.0   2.0                             2      2.0   \n",
       "4                           1.0   1.0                             1      2.0   \n",
       "..                          ...   ...                           ...      ...   \n",
       "120                         NaN   3.0                             2      1.0   \n",
       "121                         NaN   3.0                             3      NaN   \n",
       "122                         NaN   3.0                             3      NaN   \n",
       "123                         NaN   3.0                             7      1.0   \n",
       "124                         NaN   NaN                             5      3.0   \n",
       "\n",
       "                                          diet_current  diet_current_coded  \\\n",
       "0                                eat good and exercise                   1   \n",
       "1    I eat about three times a day with some snacks...                   2   \n",
       "2    toast and fruit for breakfast, salad for lunch...                   3   \n",
       "3    College diet, cheap and easy foods most nights...                   2   \n",
       "4    I try to eat healthy but often struggle becaus...                   2   \n",
       "..                                                 ...                 ...   \n",
       "120  My diet consists mainly of coffee, water, frui...                   2   \n",
       "121  A college student with an imbalanced diet tryi...                   2   \n",
       "122                             Rice, oatmeal, and tea                   2   \n",
       "123  I try to eat as healthy as possible everyday. ...                   1   \n",
       "124          high in protein and low in carbohydrates.                   1   \n",
       "\n",
       "     drink                                     eating_changes  \\\n",
       "0      1.0                                        eat faster    \n",
       "1      2.0                        I eat out more than usual.    \n",
       "2      1.0  sometimes choosing to eat fast food instead of...   \n",
       "3      2.0     Accepting cheap and premade/store bought foods   \n",
       "4      2.0  I have eaten generally the same foods but I do...   \n",
       "..     ...                                                ...   \n",
       "120    2.0  I have noticed there is less time for a prepar...   \n",
       "121    1.0  Eating Pizza as an excuse when there is nothin...   \n",
       "122    1.0                                          less rice   \n",
       "123    2.0  I don't eat as much on a daily basis since com...   \n",
       "124    1.0            I have learned to eat more vegetables.    \n",
       "\n",
       "     eating_changes_coded  eating_changes_coded1  eating_out  employment  \\\n",
       "0                       1                      1           3         3.0   \n",
       "1                       1                      2           2         2.0   \n",
       "2                       1                      3           2         3.0   \n",
       "3                       1                      3           2         3.0   \n",
       "4                       3                      4           2         2.0   \n",
       "..                    ...                    ...         ...         ...   \n",
       "120                     1                      3           2         1.0   \n",
       "121                     1                      3           4         3.0   \n",
       "122                     1                      3           3         3.0   \n",
       "123                     1                      8           5         2.0   \n",
       "124                     2                      5           1         2.0   \n",
       "\n",
       "     ethnic_food  exercise  father_education             father_profession  \\\n",
       "0              1       1.0               5.0                     profesor    \n",
       "1              4       1.0               2.0                Self employed    \n",
       "2              5       2.0               2.0                 owns business   \n",
       "3              5       3.0               2.0                     Mechanic    \n",
       "4              4       1.0               4.0                            IT   \n",
       "..           ...       ...               ...                           ...   \n",
       "120            4       2.0               4.0                   Accountant    \n",
       "121            3       2.0               5.0                        Doctor   \n",
       "122            5       2.0               5.0                CEO of company   \n",
       "123            2       1.0               3.0  Store manager at Giant Eagle   \n",
       "124            3       2.0               4.0                    Journalist   \n",
       "\n",
       "           fav_cuisine  fav_cuisine_coded  fav_food  ... healthy_feeling  \\\n",
       "0       Arabic cuisine                  3       1.0  ...               2   \n",
       "1              Italian                  1       1.0  ...               5   \n",
       "2              italian                  1       3.0  ...               6   \n",
       "3             Turkish                   3       1.0  ...               7   \n",
       "4             Italian                   1       3.0  ...               6   \n",
       "..                 ...                ...       ...  ...             ...   \n",
       "120           Italian                   1       1.0  ...               5   \n",
       "121       Mexican Food                  2       1.0  ...               5   \n",
       "122             Korean                  4       1.0  ...               6   \n",
       "123            Italian                  1       3.0  ...               1   \n",
       "124  HISPANIC CUISINE.                  2       1.0  ...               3   \n",
       "\n",
       "                                          healthy_meal  \\\n",
       "0                                      looks not oily    \n",
       "1    Grains, Veggies, (more of grains and veggies),...   \n",
       "2    usually includes natural ingredients; nonproce...   \n",
       "3             Fresh fruits& vegetables, organic meats    \n",
       "4    A lean protein such as grilled chicken, green ...   \n",
       "..                                                 ...   \n",
       "120  mainly protein and vegetables with a complex c...   \n",
       "121  A healthy meal is a variety of food , organic ...   \n",
       "122                                 lots of vegetables   \n",
       "123  A protein, a fruit, a starch, and a salad or s...   \n",
       "124              a cup of rice, vegetables, and meat.    \n",
       "\n",
       "                                            ideal_diet  ideal_diet_coded  \\\n",
       "0                                       being healthy                  8   \n",
       "1    Try to eat 5-6 small meals a day. While trying...                 3   \n",
       "2         i would say my ideal diet is my current diet                 6   \n",
       "3       Healthy, fresh veggies/fruits & organic foods                  2   \n",
       "4    Ideally I would like to be able to eat healthi...                 2   \n",
       "..                                                 ...               ...   \n",
       "120  My ideal diet would consist of a majority of w...                 6   \n",
       "121  Eating home cooked meals everyday and being ab...                 5   \n",
       "122                                    lots of veggies                 2   \n",
       "123  My ideal diet is the diet i am currently on.  ...                 6   \n",
       "124  Being able to balance between sweets, vegetabl...                 3   \n",
       "\n",
       "     income  indian_food italian_food life_rewarding  marital_status  \\\n",
       "0       5.0            5            5            1.0             1.0   \n",
       "1       4.0            4            4            1.0             2.0   \n",
       "2       6.0            5            5            7.0             2.0   \n",
       "3       6.0            5            5            2.0             2.0   \n",
       "4       6.0            2            5            1.0             1.0   \n",
       "..      ...          ...          ...            ...             ...   \n",
       "120     4.0            3            5            7.0             1.0   \n",
       "121     2.0            5            5            7.0             1.0   \n",
       "122     2.0            5            3           10.0             1.0   \n",
       "123     4.0            1            5            1.0             1.0   \n",
       "124     5.0            2            3            5.0             2.0   \n",
       "\n",
       "                                   meals_dinner_friend  mother_education  \\\n",
       "0                                 rice, chicken,  soup               1.0   \n",
       "1                               Pasta, steak, chicken                4.0   \n",
       "2    chicken and rice with veggies, pasta, some kin...               2.0   \n",
       "3     Grilled chicken \\rStuffed Shells\\rHomemade Chili               4.0   \n",
       "4    Chicken Parmesan, Pulled Pork, Spaghetti and m...               5.0   \n",
       "..                                                 ...               ...   \n",
       "120                                 pasta, fish, steak               3.0   \n",
       "121        Fried Rice \\rBaked potatoes \\rCurry Chicken               2.0   \n",
       "122                                 meat, rice, kimchi               1.0   \n",
       "123                       Pizza, Spaghetti, Baked Ziti               2.0   \n",
       "124                        Vegetables, Meat, and rice.               3.0   \n",
       "\n",
       "                             mother_profession  nutritional_check  \\\n",
       "0                                   unemployed                  5   \n",
       "1                                    Nurse RN                   4   \n",
       "2                                owns business                  4   \n",
       "3                    Special Education Teacher                  2   \n",
       "4                     Substance Abuse Conselor                  3   \n",
       "..                                         ...                ...   \n",
       "120                   Radiological Technician                   5   \n",
       "121                     Public Health Advisor                   3   \n",
       "122                       Real Estate manageer                  3   \n",
       "123  Receptionist for a medical supply company                  4   \n",
       "124                                 House-wife                  5   \n",
       "\n",
       "     on_off_campus parents_cook  pay_meal_out persian_food  \\\n",
       "0              1.0            1             2          5.0   \n",
       "1              1.0            1             4          4.0   \n",
       "2              2.0            1             3          5.0   \n",
       "3              1.0            1             2          5.0   \n",
       "4              1.0            1             4          2.0   \n",
       "..             ...          ...           ...          ...   \n",
       "120            3.0            1             4          3.0   \n",
       "121            1.0            3             4          1.0   \n",
       "122            1.0            2             4          5.0   \n",
       "123            1.0            2             3          1.0   \n",
       "124            1.0            3             3          2.0   \n",
       "\n",
       "     self_perception_weight  soup  sports  thai_food  tortilla_calories  \\\n",
       "0                       3.0   1.0     1.0          1             1165.0   \n",
       "1                       3.0   1.0     1.0          2              725.0   \n",
       "2                       6.0   1.0     2.0          5             1165.0   \n",
       "3                       5.0   1.0     2.0          5              725.0   \n",
       "4                       4.0   1.0     1.0          4              940.0   \n",
       "..                      ...   ...     ...        ...                ...   \n",
       "120                     4.0   1.0     1.0          5              940.0   \n",
       "121                     4.0   1.0     NaN          4              940.0   \n",
       "122                     4.0   1.0     2.0          5              580.0   \n",
       "123                     2.0   2.0     2.0          1              940.0   \n",
       "124                     3.0   1.0     2.0          2              725.0   \n",
       "\n",
       "     turkey_calories  type_sports  veggies_day  vitamins  waffle_calories  \\\n",
       "0                345   car racing            5         1             1315   \n",
       "1                690  Basketball             4         2              900   \n",
       "2                500         none            5         1              900   \n",
       "3                690          NaN            3         1             1315   \n",
       "4                500     Softball            4         2              760   \n",
       "..               ...          ...          ...       ...              ...   \n",
       "120              500     Softball            5         1             1315   \n",
       "121              500  basketball             5         2             1315   \n",
       "122              690         none            4         2             1315   \n",
       "123              500          NaN            3         1             1315   \n",
       "124              345          NaN            4         2              575   \n",
       "\n",
       "                       weight  \n",
       "0                         187  \n",
       "1                         155  \n",
       "2    I'm not answering this.   \n",
       "3               Not sure, 240  \n",
       "4                         190  \n",
       "..                        ...  \n",
       "120                       156  \n",
       "121                       180  \n",
       "122                       120  \n",
       "123                       135  \n",
       "124                       135  \n",
       "\n",
       "[125 rows x 61 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = 'data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)\n",
    "\n",
    "df_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPA                 123\n",
       "Gender              125\n",
       "breakfast           125\n",
       "calories_chicken    125\n",
       "calories_day        106\n",
       "                   ... \n",
       "type_sports          99\n",
       "veggies_day         125\n",
       "vitamins            125\n",
       "waffle_calories     125\n",
       "weight              123\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "\n",
    "df_food.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "df_food.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we’d like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. …and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ‘em.\n",
    "df_food_new=df_food.drop(columns=[ 'type_sports','mother_education', 'mother_profession','father_education','father_profession','cuisine','comfort_food_reasons_coded','GPA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                           0\n",
       "breakfast                        0\n",
       "calories_chicken                 0\n",
       "calories_day                    19\n",
       "calories_scone                   1\n",
       "coffee                           0\n",
       "comfort_food                     1\n",
       "comfort_food_reasons             2\n",
       "cook                             3\n",
       "comfort_food_reasons_coded.1     0\n",
       "diet_current                     1\n",
       "diet_current_coded               0\n",
       "drink                            2\n",
       "eating_changes                   3\n",
       "eating_changes_coded             0\n",
       "eating_changes_coded1            0\n",
       "eating_out                       0\n",
       "employment                       9\n",
       "ethnic_food                      0\n",
       "exercise                        13\n",
       "fav_cuisine                      2\n",
       "fav_cuisine_coded                0\n",
       "fav_food                         2\n",
       "food_childhood                   1\n",
       "fries                            0\n",
       "fruit_day                        0\n",
       "grade_level                      0\n",
       "greek_food                       0\n",
       "healthy_feeling                  0\n",
       "healthy_meal                     1\n",
       "ideal_diet                       1\n",
       "ideal_diet_coded                 0\n",
       "income                           1\n",
       "indian_food                      0\n",
       "italian_food                     0\n",
       "life_rewarding                   1\n",
       "marital_status                   1\n",
       "meals_dinner_friend              3\n",
       "nutritional_check                0\n",
       "on_off_campus                    1\n",
       "parents_cook                     0\n",
       "pay_meal_out                     0\n",
       "persian_food                     1\n",
       "self_perception_weight           1\n",
       "soup                             1\n",
       "sports                           2\n",
       "thai_food                        0\n",
       "tortilla_calories                1\n",
       "turkey_calories                  0\n",
       "veggies_day                      0\n",
       "vitamins                         0\n",
       "waffle_calories                  0\n",
       "weight                           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ‘em.\n",
    "\n",
    "df_food_new.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s―the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 82 entries, 1 to 123\n",
      "Data columns (total 53 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Gender                        82 non-null     int64  \n",
      " 1   breakfast                     82 non-null     int64  \n",
      " 2   calories_chicken              82 non-null     int64  \n",
      " 3   calories_day                  82 non-null     float64\n",
      " 4   calories_scone                82 non-null     float64\n",
      " 5   coffee                        82 non-null     int64  \n",
      " 6   comfort_food                  82 non-null     object \n",
      " 7   comfort_food_reasons          82 non-null     object \n",
      " 8   cook                          82 non-null     float64\n",
      " 9   comfort_food_reasons_coded.1  82 non-null     int64  \n",
      " 10  diet_current                  82 non-null     object \n",
      " 11  diet_current_coded            82 non-null     int64  \n",
      " 12  drink                         82 non-null     float64\n",
      " 13  eating_changes                82 non-null     object \n",
      " 14  eating_changes_coded          82 non-null     int64  \n",
      " 15  eating_changes_coded1         82 non-null     int64  \n",
      " 16  eating_out                    82 non-null     int64  \n",
      " 17  employment                    82 non-null     float64\n",
      " 18  ethnic_food                   82 non-null     int64  \n",
      " 19  exercise                      82 non-null     float64\n",
      " 20  fav_cuisine                   82 non-null     object \n",
      " 21  fav_cuisine_coded             82 non-null     int64  \n",
      " 22  fav_food                      82 non-null     float64\n",
      " 23  food_childhood                82 non-null     object \n",
      " 24  fries                         82 non-null     int64  \n",
      " 25  fruit_day                     82 non-null     int64  \n",
      " 26  grade_level                   82 non-null     int64  \n",
      " 27  greek_food                    82 non-null     int64  \n",
      " 28  healthy_feeling               82 non-null     int64  \n",
      " 29  healthy_meal                  82 non-null     object \n",
      " 30  ideal_diet                    82 non-null     object \n",
      " 31  ideal_diet_coded              82 non-null     int64  \n",
      " 32  income                        82 non-null     float64\n",
      " 33  indian_food                   82 non-null     int64  \n",
      " 34  italian_food                  82 non-null     int64  \n",
      " 35  life_rewarding                82 non-null     float64\n",
      " 36  marital_status                82 non-null     float64\n",
      " 37  meals_dinner_friend           82 non-null     object \n",
      " 38  nutritional_check             82 non-null     int64  \n",
      " 39  on_off_campus                 82 non-null     float64\n",
      " 40  parents_cook                  82 non-null     int64  \n",
      " 41  pay_meal_out                  82 non-null     int64  \n",
      " 42  persian_food                  82 non-null     float64\n",
      " 43  self_perception_weight        82 non-null     float64\n",
      " 44  soup                          82 non-null     float64\n",
      " 45  sports                        82 non-null     float64\n",
      " 46  thai_food                     82 non-null     int64  \n",
      " 47  tortilla_calories             82 non-null     float64\n",
      " 48  turkey_calories               82 non-null     int64  \n",
      " 49  veggies_day                   82 non-null     int64  \n",
      " 50  vitamins                      82 non-null     int64  \n",
      " 51  waffle_calories               82 non-null     int64  \n",
      " 52  weight                        82 non-null     object \n",
      "dtypes: float64(16), int64(27), object(10)\n",
      "memory usage: 34.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop ‘em.\n",
    "\n",
    "\n",
    "df_food_new=df_food_new.dropna()\n",
    "df_food_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Fix that.\n",
    "\n",
    "#1\n",
    "numeric_columns = df_food_new.select_dtypes(include=['int64', 'float64']).columns\n",
    "non_numeric_counts = df_food_new[numeric_columns].apply(lambda col: pd.to_numeric(col, errors='coerce').isna().sum())\n",
    "print(non_numeric_counts[non_numeric_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Using this we can find out which column has string value instead of int and float.\n",
    "# We can make all column to be int or float or string. column can't be mixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Then we can chnage our String values to numberic or avg from others. \n",
    "problematic_columns = ['calories_day', 'calories_scone', 'cook', 'drink', 'employment', \n",
    "                       'exercise', 'fav_food', 'income', 'life_rewarding', 'marital_status', \n",
    "                       'on_off_campus', 'persian_food', 'self_perception_weight', 'soup', \n",
    "                       'sports', 'tortilla_calories']\n",
    "\n",
    "\n",
    "for column in problematic_columns:\n",
    "    \n",
    "    non_numeric_rows = df_food_new[pd.to_numeric(df_food_new[column], errors='coerce').isna()]\n",
    "    \n",
    "    \n",
    "    if not non_numeric_rows.empty:\n",
    "        print(f\"Column '{column}' has the following non-numeric values:\")\n",
    "        print(non_numeric_rows[[column]]) \n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problematic_columns = ['calories_day', 'calories_scone', 'cook', 'drink', 'employment', \n",
    "                       'exercise', 'fav_food', 'income', 'life_rewarding', 'marital_status', \n",
    "                       'on_off_campus', 'persian_food', 'self_perception_weight', 'soup', \n",
    "                       'sports', 'tortilla_calories']\n",
    "\n",
    "for column in problematic_columns:\n",
    "\n",
    "    non_numeric_rows = df_food_new[pd.to_numeric(df_food_new[column], errors='coerce').isna()]\n",
    "    \n",
    "    if not non_numeric_rows.empty:\n",
    "        print(f\"Column '{column}' has the following non-numeric values:\")\n",
    "        print(non_numeric_rows[[column]])  \n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! 😁\n",
    "\n",
    "Let’s save it somewhere to be shipped off to another teammate. 💾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "\n",
    "df_food_new.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "\n",
    "df_salary=pd.read_csv('data/Ask_A_Manager_Salary_Survey 2021_(Responses)_Form_Responses_1.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? 🙃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418394"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. I’m dead serious.\n",
    "\n",
    "df_salary.count().sum()\n",
    "\n",
    "# 418394 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28062 entries, 0 to 28061\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                                                                                                                                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                                                --------------  -----  \n",
      " 0   Timestamp                                                                                                                                                                                                                             28062 non-null  object \n",
      " 1   How old are you?                                                                                                                                                                                                                      28062 non-null  object \n",
      " 2   What industry do you work in?                                                                                                                                                                                                         27988 non-null  object \n",
      " 3   Job title                                                                                                                                                                                                                             28061 non-null  object \n",
      " 4   If your job title needs additional context, please clarify here:                                                                                                                                                                      7262 non-null   object \n",
      " 5   What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  28062 non-null  object \n",
      " 6   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                        20766 non-null  float64\n",
      " 7   Please indicate the currency                                                                                                                                                                                                          28062 non-null  object \n",
      " 8   If \"Other,\" please indicate the currency here:                                                                                                                                                                                        206 non-null    object \n",
      " 9   If your income needs additional context, please provide it here:                                                                                                                                                                      3042 non-null   object \n",
      " 10  What country do you work in?                                                                                                                                                                                                          28062 non-null  object \n",
      " 11  If you're in the U.S., what state do you work in?                                                                                                                                                                                     23039 non-null  object \n",
      " 12  What city do you work in?                                                                                                                                                                                                             27980 non-null  object \n",
      " 13  How many years of professional work experience do you have overall?                                                                                                                                                                   28062 non-null  object \n",
      " 14  How many years of professional work experience do you have in your field?                                                                                                                                                             28062 non-null  object \n",
      " 15  What is your highest level of education completed?                                                                                                                                                                                    27840 non-null  object \n",
      " 16  What is your gender?                                                                                                                                                                                                                  27891 non-null  object \n",
      " 17  What is your race? (Choose all that apply.)                                                                                                                                                                                           27885 non-null  object \n",
      "dtypes: float64(1), object(17)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "\n",
    "df_salary.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh… Ugh! Give these columns easier names to work with first. 🙄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                       industry  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                      title title_context  salary  \\\n",
       "0        Research and Instruction Librarian           NaN  55,000   \n",
       "1  Change & Internal Communications Manager           NaN  54,600   \n",
       "2                      Marketing Specialist           NaN  34,000   \n",
       "3                           Program Manager           NaN  62,000   \n",
       "4                        Accounting Manager           NaN  60,000   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context  \\\n",
       "0                      0.0      USD            NaN            NaN   \n",
       "1                   4000.0      GBP            NaN            NaN   \n",
       "2                      NaN      USD            NaN            NaN   \n",
       "3                   3000.0      USD            NaN            NaN   \n",
       "4                   7000.0      USD            NaN            NaN   \n",
       "\n",
       "          country           state         city     total_yoe    field_yoe  \\\n",
       "0   United States   Massachusetts       Boston     5-7 years    5-7 years   \n",
       "1  United Kingdom             NaN    Cambridge  8 - 10 years    5-7 years   \n",
       "2              US       Tennessee  Chattanooga   2 - 4 years  2 - 4 years   \n",
       "3             USA       Wisconsin    Milwaukee  8 - 10 years    5-7 years   \n",
       "4              US  South Carolina   Greenville  8 - 10 years    5-7 years   \n",
       "\n",
       "  highest_education_completed      gender   race  \n",
       "0             Master's degree       Woman  White  \n",
       "1              College degree  Non-binary  White  \n",
       "2              College degree       Woman  White  \n",
       "3              College degree       Woman  White  \n",
       "4              College degree       Woman  White  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename ‘em.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed, gender, race\n",
    "\n",
    "df_salary.columns = [\n",
    "    'timestamp', 'age', 'industry', 'title', 'title_context', 'salary', \n",
    "    'additional_compensation', 'currency', 'other_currency', 'salary_context', \n",
    "    'country', 'state', 'city', 'total_yoe', 'field_yoe', \n",
    "    'highest_education_completed', 'gender', 'race'\n",
    "]\n",
    "df_salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s a lot, and that should not have been easy. 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech                          4699\n",
       "Education (Higher Education)               2464\n",
       "Nonprofits                                 2419\n",
       "Health care                                1896\n",
       "Government and Public Administration       1889\n",
       "                                           ... \n",
       "Gaming (Gambling)                             1\n",
       "Regulatory Affairs- nutraceuticals            1\n",
       "Manufacturing : corporate admin support       1\n",
       "Real Estate Investment Support                1\n",
       "Wine & Spirits                                1\n",
       "Name: count, Length: 1219, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "df_salary['industry'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you’re looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "\n",
    "df_salary_tech = df_salary[df_salary['industry'] == 'Computing or Tech'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech    4699\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check \n",
    "\n",
    "df_salary_tech.head()\n",
    "\n",
    "df_salary_tech['industry'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars 💵 is a euro 💶 or a pound 💷? That sounds like a problem for another day. 🫠\n",
    "\n",
    "For now, let’s just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187,500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110,000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144,600</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:04:09</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Design Director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200,850</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age           industry                        title  \\\n",
       "0  4/27/2021 11:03:01  45-54  Computing or Tech              Systems Analyst   \n",
       "1  4/27/2021 11:04:04  25-34  Computing or Tech  Principal Software Engineer   \n",
       "2  4/27/2021 11:04:04  25-34  Computing or Tech         Intelligence Analyst   \n",
       "3  4/27/2021 11:04:07  35-44  Computing or Tech             Mobile developer   \n",
       "4  4/27/2021 11:04:09  35-44  Computing or Tech      Product Design Director   \n",
       "\n",
       "                  title_context   salary  additional_compensation currency  \\\n",
       "0  Data developer/ETL Developer  112,000                  10000.0      USD   \n",
       "1                           NaN  187,500                   5000.0      USD   \n",
       "2                           NaN  110,000                  20000.0      USD   \n",
       "3                           NaN  144,600                   2500.0      USD   \n",
       "4                           NaN  200,850                  40000.0      USD   \n",
       "\n",
       "  other_currency                 salary_context        country  \\\n",
       "0            NaN                            NaN             US   \n",
       "1            NaN                            NaN  United States   \n",
       "2            NaN  Around 20,000 a year in stock            USA   \n",
       "3            NaN                            NaN            USA   \n",
       "4            NaN                            NaN            USA   \n",
       "\n",
       "            state           city      total_yoe      field_yoe  \\\n",
       "0        Missouri      St. Louis  21 - 30 years  21 - 30 years   \n",
       "1    Pennsylvania     Pittsburgh   8 - 10 years      5-7 years   \n",
       "2        Virginia  Arlington, VA   8 - 10 years   8 - 10 years   \n",
       "3   Massachusetts         Boston      5-7 years      5-7 years   \n",
       "4  North Carolina    Chapel Hill  11 - 20 years  11 - 20 years   \n",
       "\n",
       "  highest_education_completed gender   race  \n",
       "0              College degree  Woman  White  \n",
       "1              College degree  Woman  White  \n",
       "2             Master's degree    Man  White  \n",
       "3                         PhD  Woman  White  \n",
       "4              College degree  Woman  White  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "df_salary_tech_usd=df_salary_tech[df_salary_tech['currency']=='USD'].reset_index(drop=True)\n",
    "df_salary_tech_usd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "us                           3561\n",
      "united states                  68\n",
      "usa                            58\n",
      "united states of america        7\n",
      "u.s.a.                          7\n",
      "israel                          5\n",
      "canada                          4\n",
      "u.s                             2\n",
      "u.s.                            2\n",
      "unite states                    2\n",
      "united state of america         2\n",
      "brazil                          2\n",
      "united kingdom                  2\n",
      "india                           2\n",
      "australia                       2\n",
      "singapore                       2\n",
      "denmark                         2\n",
      "u.s.a                           2\n",
      "unitedstates                    2\n",
      "new zealand                     2\n",
      "france                          2\n",
      "spain                           2\n",
      "poland                          2\n",
      "mexico                          1\n",
      "danmark                         1\n",
      "united stated                   1\n",
      "cuba                            1\n",
      "remote (philippines)            1\n",
      "united state                    1\n",
      "uruguay                         1\n",
      " us                             1\n",
      "united stateds                  1\n",
      "puerto rico                     1\n",
      "canada                          1\n",
      "isa                             1\n",
      "pakistan                        1\n",
      "america                         1\n",
      "uniyed states                   1\n",
      "netherlands                     1\n",
      "italy                           1\n",
      "jamaica                         1\n",
      "international                   1\n",
      "thailand                        1\n",
      "unites states                   1\n",
      "romania                         1\n",
      "japan                           1\n",
      "us                              1\n",
      "united stares                   1\n",
      "australian                      1\n",
      "china                           1\n",
      "san francisco                   1\n",
      "u.s.a                           1\n",
      "colombia                        1\n",
      "ghana                           1\n",
      "nigeria                         1\n",
      "ss                              1\n",
      "nigeria                         1\n",
      "burma                           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "condition1=df_salary_tech_usd['country'].value_counts().sort_values(ascending=False)\n",
    "print(condition1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can’t get our answers with what we currently have, so you’ll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value―say, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace them all with 'US'.\n",
    "us_name = [name.lower() for name in ['United States', 'USA', 'US', 'U.S.', 'United States of America','U.S.A.']]\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].str.lower()\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].str.strip()\n",
    "df_salary_tech_usd['country']=df_salary_tech_usd['country'].replace(us_name,'US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "US                         3705\n",
      "israel                        5\n",
      "canada                        5\n",
      "u.s.a                         3\n",
      "brazil                        2\n",
      "australia                     2\n",
      "unite states                  2\n",
      "united kingdom                2\n",
      "u.s                           2\n",
      "singapore                     2\n",
      "spain                         2\n",
      "unitedstates                  2\n",
      "united state of america       2\n",
      "poland                        2\n",
      "france                        2\n",
      "denmark                       2\n",
      "nigeria                       2\n",
      "new zealand                   2\n",
      "india                         2\n",
      "cuba                          1\n",
      "netherlands                   1\n",
      "united state                  1\n",
      "pakistan                      1\n",
      "isa                           1\n",
      "united stateds                1\n",
      "uruguay                       1\n",
      "mexico                        1\n",
      "danmark                       1\n",
      "italy                         1\n",
      "international                 1\n",
      "remote (philippines)          1\n",
      "china                         1\n",
      "san francisco                 1\n",
      "united stated                 1\n",
      "jamaica                       1\n",
      "ss                            1\n",
      "uniyed states                 1\n",
      "ghana                         1\n",
      "colombia                      1\n",
      "thailand                      1\n",
      "unites states                 1\n",
      "romania                       1\n",
      "australian                    1\n",
      "united stares                 1\n",
      "puerto rico                   1\n",
      "japan                         1\n",
      "america                       1\n",
      "burma                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count again.\n",
    "condition1=df_salary_tech_usd['country'].value_counts().sort_values(ascending=False)\n",
    "print(condition1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].str.lower()\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].str.strip() \n",
    "us_name = [name.lower() for name in ['United States', 'USA', 'US', 'U.S.', 'United States of America','u.s.a', 'u.s.a.']]\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country'].replace(us_name, 'US')\n",
    "df_salary_tech_usd['country'] = df_salary_tech_usd['country']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "US                         3708\n",
      "israel                        5\n",
      "canada                        5\n",
      "singapore                     2\n",
      "france                        2\n",
      "nigeria                       2\n",
      "australia                     2\n",
      "denmark                       2\n",
      "india                         2\n",
      "u.s                           2\n",
      "unite states                  2\n",
      "spain                         2\n",
      "united state of america       2\n",
      "united kingdom                2\n",
      "new zealand                   2\n",
      "poland                        2\n",
      "brazil                        2\n",
      "unitedstates                  2\n",
      "italy                         1\n",
      "united stateds                1\n",
      "uruguay                       1\n",
      "remote (philippines)          1\n",
      "united stated                 1\n",
      "international                 1\n",
      "united state                  1\n",
      "danmark                       1\n",
      "cuba                          1\n",
      "puerto rico                   1\n",
      "america                       1\n",
      "uniyed states                 1\n",
      "pakistan                      1\n",
      "isa                           1\n",
      "australian                    1\n",
      "mexico                        1\n",
      "colombia                      1\n",
      "ss                            1\n",
      "netherlands                   1\n",
      "china                         1\n",
      "san francisco                 1\n",
      "romania                       1\n",
      "ghana                         1\n",
      "jamaica                       1\n",
      "japan                         1\n",
      "unites states                 1\n",
      "thailand                      1\n",
      "united stares                 1\n",
      "burma                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BONUS CREDIT: if you’ve resolved it, let’s see how well you did by counting the number of instances of each unique value.\n",
    "\n",
    "condition1=df_salary_tech_usd['country'].value_counts().sort_values(ascending=False)\n",
    "print(condition1)\n",
    "\n",
    "#whatever is not counting as US, are misspelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s looking good so far. Let’s find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1942\u001b[0m     res_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grouper\u001b[39m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1943\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    862\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    866\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 885\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m    886\u001b[0m     res \u001b[39m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2451\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2452\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m-> 2454\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mmean(numeric_only\u001b[39m=\u001b[39mnumeric_only),\n\u001b[1;32m   2455\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[1;32m   2456\u001b[0m     )\n\u001b[1;32m   2457\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[39m@doc\u001b[39m(make_doc(\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39mmean(\u001b[39mself\u001b[39m, axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stat_function(\n\u001b[1;32m  12421\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m, nanops\u001b[39m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m  12422\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[39m\"\u001b[39m\u001b[39mskipna\u001b[39m\u001b[39m\"\u001b[39m, none_allowed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reduce(\n\u001b[1;32m  12378\u001b[0m     func, name\u001b[39m=\u001b[39mname, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, numeric_only\u001b[39m=\u001b[39mnumeric_only\n\u001b[1;32m  12379\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6453\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not allow \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnumeric_only\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith non-numeric dtypes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, mask\u001b[39m=\u001b[39mmask, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39msum(axis, dtype\u001b[39m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m     \u001b[39m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not convert string \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to numeric\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string '75,00070,00072,00052,00029,120105,000120,00052000550009500035000035000' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[245], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Find the minimum, mean, and maximum salary in USD by U.S. state.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_us \u001b[39m=\u001b[39m df_salary_tech_usd[df_salary_tech_usd[\u001b[39m'\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mUS\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m salary_stats_by_state \u001b[39m=\u001b[39m df_us\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39msalary\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39magg([\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      4\u001b[0m salary_stats_by_state \u001b[39m=\u001b[39m salary_stats_by_state\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(salary_stats_by_state)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:257\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mengine\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m engine\n\u001b[1;32m    256\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 257\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m relabeling:\n\u001b[1;32m    259\u001b[0m     \u001b[39m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39massert\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:362\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (name, func) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arg):\n\u001b[1;32m    361\u001b[0m         key \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mOutputKey(label\u001b[39m=\u001b[39mname, position\u001b[39m=\u001b[39midx)\n\u001b[0;32m--> 362\u001b[0m         results[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, DataFrame) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    365\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:249\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m engine_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mengine_kwargs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, func)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    251\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, abc\u001b[39m.\u001b[39mIterable):\n\u001b[1;32m    252\u001b[0m     \u001b[39m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[39m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2446\u001b[0m         grouped_mean,\n\u001b[1;32m   2447\u001b[0m         executor\u001b[39m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2448\u001b[0m         engine_kwargs,\n\u001b[1;32m   2449\u001b[0m         min_periods\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m   2450\u001b[0m     )\n\u001b[1;32m   2451\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2452\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2454\u001b[0m         alt\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: Series(x, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mmean(numeric_only\u001b[39m=\u001b[39mnumeric_only),\n\u001b[1;32m   2455\u001b[0m         numeric_only\u001b[39m=\u001b[39mnumeric_only,\n\u001b[1;32m   2456\u001b[0m     )\n\u001b[1;32m   2457\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgroupby\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1998\u001b[0m new_mgr \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   1999\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2000\u001b[0m \u001b[39mif\u001b[39;00m how \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39midxmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39midxmax\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/base.py:367\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrouped_reduce\u001b[39m(\u001b[39mself\u001b[39m, func):\n\u001b[1;32m    366\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marray\n\u001b[0;32m--> 367\u001b[0m     res \u001b[39m=\u001b[39m func(arr)\n\u001b[1;32m    368\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(res))\n\u001b[1;32m    370\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m   1994\u001b[0m \u001b[39massert\u001b[39;00m alt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1995\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39mndim, alt\u001b[39m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1944\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39magg function failed [how->\u001b[39m\u001b[39m{\u001b[39;00mhow\u001b[39m}\u001b[39;00m\u001b[39m,dtype->\u001b[39m\u001b[39m{\u001b[39;00mser\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1945\u001b[0m     \u001b[39m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1946\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(err)(msg) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39mif\u001b[39;00m ser\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m   1949\u001b[0m     res_values \u001b[39m=\u001b[39m res_values\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn’t numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          state       min           mean        max\n",
      "35  Michigan, Texas, Washington  340000.0  340000.000000   340000.0\n",
      "10           California, Oregon  200000.0  200000.000000   200000.0\n",
      "8          California, Colorado  176000.0  176000.000000   176000.0\n",
      "18       Georgia, Massachusetts  175000.0  175000.000000   175000.0\n",
      "16                      Florida   28800.0  157457.232143  2600000.0\n",
      "..                          ...       ...            ...        ...\n",
      "32  Massachusetts, Pennsylvania   83000.0   83000.000000    83000.0\n",
      "6                      Arkansas   55000.0   81682.300000   144000.0\n",
      "9          California, Maryland   81500.0   81500.000000    81500.0\n",
      "26                    Louisiana   35360.0   76596.000000   110000.0\n",
      "2              Alabama, Montana   72000.0   72000.000000    72000.0\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/jr0rzgxx39j6pgvlp2j2z5jw0000gn/T/ipykernel_77757/4097033487.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_us['salary'] = df_us['salary'].replace(',', '', regex=True).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Fix it.\n",
    "df_us = df_salary_tech_usd[df_salary_tech_usd['country'] == 'US']\n",
    "df_us['salary'] = df_us['salary'].replace(',', '', regex=True).astype(float)\n",
    "\n",
    "\n",
    "\n",
    "salary_stats_by_state = df_us.groupby('state')['salary'].agg(['min', 'mean', 'max']).reset_index()\n",
    "salary_stats_by_state = salary_stats_by_state.sort_values(by='mean', ascending=False)\n",
    "\n",
    "print(salary_stats_by_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          state       min       mean        max\n",
      "35  Michigan, Texas, Washington  340000.0  340000.00   340000.0\n",
      "10           California, Oregon  200000.0  200000.00   200000.0\n",
      "8          California, Colorado  176000.0  176000.00   176000.0\n",
      "18       Georgia, Massachusetts  175000.0  175000.00   175000.0\n",
      "16                      Florida   28800.0  157457.23  2600000.0\n",
      "..                          ...       ...        ...        ...\n",
      "32  Massachusetts, Pennsylvania   83000.0   83000.00    83000.0\n",
      "6                      Arkansas   55000.0   81682.30   144000.0\n",
      "9          California, Maryland   81500.0   81500.00    81500.0\n",
      "26                    Louisiana   35360.0   76596.00   110000.0\n",
      "2              Alabama, Montana   72000.0   72000.00    72000.0\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Try it again. Yeah!\n",
    "\n",
    "\n",
    "salary_stats_by_state = df_us.groupby('state')['salary'].agg(['min', 'mean', 'max']).reset_index()\n",
    "salary_stats_by_state[['min', 'mean', 'max']] = salary_stats_by_state[['min', 'mean', 'max']].round(2)\n",
    "\n",
    "salary_stats_by_state = salary_stats_by_state.sort_values(by='mean', ascending=False)\n",
    "\n",
    "print(salary_stats_by_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let’s narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            state       min      mean       max\n",
      "35    Michigan, Texas, Washington  340000.0  340000.0  340000.0\n",
      "10             California, Oregon  200000.0  200000.0  200000.0\n",
      "8            California, Colorado  176000.0  176000.0  176000.0\n",
      "18         Georgia, Massachusetts  175000.0  175000.0  175000.0\n",
      "1   Alabama, District of Columbia  156000.0  156000.0  156000.0\n",
      "..                            ...       ...       ...       ...\n",
      "32    Massachusetts, Pennsylvania   83000.0   83000.0   83000.0\n",
      "6                        Arkansas   55000.0   81682.3  144000.0\n",
      "9            California, Maryland   81500.0   81500.0   81500.0\n",
      "26                      Louisiana   35360.0   76596.0  110000.0\n",
      "2                Alabama, Montana   72000.0   72000.0   72000.0\n",
      "\n",
      "[66 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qf/jr0rzgxx39j6pgvlp2j2z5jw0000gn/T/ipykernel_77757/3752681102.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_us['timestamp'] = pd.to_datetime(df_us['timestamp'])\n",
      "/var/folders/qf/jr0rzgxx39j6pgvlp2j2z5jw0000gn/T/ipykernel_77757/3752681102.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_us['year'] = df_us['timestamp'].dt.year\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "\n",
    "df_us['timestamp'] = pd.to_datetime(df_us['timestamp'])\n",
    "df_us['year'] = df_us['timestamp'].dt.year\n",
    "df_filtered = df_us[df_us['year'].isin([2021, 2022, 2023])]\n",
    "salary_stats_filtered = df_filtered.groupby('state')['salary'].agg(['min', 'mean', 'max']).reset_index()\n",
    "salary_stats_filtered[['min', 'mean', 'max']] = salary_stats_filtered[['min', 'mean', 'max']].round(2)\n",
    "salary_stats_filtered = salary_stats_filtered.sort_values(by='mean', ascending=False)\n",
    "print(salary_stats_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you’ve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let’s back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bonus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum―say 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you―like say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* 😜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
